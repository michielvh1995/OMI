\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{cite}

\title{Research Plan Force-directed Graph Drawing}
\author{
  Michiel van Heusden, 4173309 \and
  Maurits van der Veen, 4167287 \and
  Kevin Oosterlaak, 4012372 \and
  Jesse Ceelen, 4061837
  }
\date{\today}

\begin{document}
  \maketitle
  \tableofcontents
  \section{intro}
  Data requires often visualization before people understand what it means.
  This visualization is done with graphs and charts.
  This research focuses on the drawing methods of graphs.
  These graphs consist of objects and the relations between them.
  In graph theory the objects are called vertices and their relations edges.\cite{bondy1976graph}
  Generating readable graphs becomes more difficult as the amount of vertices and edges grows.
  To generate these correctly many algorithms were developed.
  One family of algorithms to do this is called \emph{Force Directed Graph Drawing}.
  The idea behind force directed graph drawing is to treat the graph as a physical system and iterate on the forces acting on it until the result stabilizes. In this research several of these algorithms will be tested and compared to see which generates the most readable graphs.
  Not only will we compare different algorithms, we will also look at how the parameters of these algorithms affect the results.

  \subsection{The Algorithms}\label{par:algorithms}
    The method used for each of the tests is the same,  except for the way the forces are calculated.
    Said method is for each vertex to iterate over the other vertices and calculate the repulsive force between them.
    Then the same is done for the attractive force, but instead of iterating over vertices it iterates over all vertices connected to the current vertex by an edge. All of these forces are added together and applied to the vertex.
    
    The above is applied to every vertex, and after a sufficiently large amount of iterations the graph should have converged to a stable configuration.

    \subsubsection{Hooke-Coulomb}
    The Hooke-Coulomb algorithm is not named after its inventors, but after the laws it follows.
    The attractive forces are calculated using Hooke's Spring Law.
    The repulsive ones are based on particle physics.
    To be more precise, they are calculated using Coulomb's law of charged particles.

    Hooke's Law can be used to calculate the distance a spring extends when a certain force is applied to it.
    However, this same law can be used to calculate the required force for a spring to be extended a certain distance.
    The law itself is rather simple:
    \begin{equation}
      F = c \delta X
    \end{equation}
    Here $c$ is a constant that defines the stiffness of the spring, it is also known as te \emph{spring constant}.
    The change in length is $\delta X$, whilst $F$ is the required force.

    Coulomb's law was first published by the French physicist Charles Augustin de Coulomb in 1785.\cite{coulomb1785premier}
    Though it was first proposed for charged metal balls, it holds for charged particles.
    In his book Coulomb states for two equally electrified metal balls "\ldots the repulsive force that the two balls \ldots exert on each other, follows the inverse proportion of the square of the distance".
    This means that the repulsive force grows quadratic the closer the balls are.
    Coulomb's law can be written down as an equation as well:
    \begin{equation}
      F = k_e \frac{q_1 q_2}{r^2}
    \end{equation}
     In this equation $q_1$ and $q_2$ are the charges of the particles, $r$ is the distance between them and $k_e$ is Coulomb's Constant.\footnote{$k_e = 8.987551787 x 10^9 N m^2 C^{-2}$}

    Changing Hooke's Law to make it useful for the calculation of forces is rather straightforeward:
    Each edge corresponds to a spring, where the vertices are objects connected by springs.
    Thus we can state a rest length $l_0$ for each edge, for easy calculations we have decided on $l_0 = 1$.
    Using the ideal length -- which can be seen as the starting length of the spring -- it is possible to calculate $\delta X$:
    \begin{equation}
      \delta X =  l_d - l_0
    \end{equation}
    In this formula $l_d$ is the distance between the two connected vertices.
    The resulting formula for the attractive forces between vertices $i$ and $j$ will thus be:
    \begin{equation}
      F_a (i,j) = w_{a} (l_d - l_0) \hat{r}_{i,j}
    \end{equation}
    In this formula the constant $w_{a}$ is used instead of $c$ for future ease of distinguishing between the constants used in various formulas.
    Not only could $w_{a}$ be seen as the stiffness of the spring, it could also be seen as the weight of the attractive force, hence the new name.
    Thus it can be used to control how much influence the spring has on the vertex. $\hat{r}_{i,j}$ is the normalized vector from vector $i$ to vector $j$, calculated as $\hat{r}_{i,j} = \vec{r_{i,j}} / |\vec{r_{i,j}}|$ with $\vec{r_{i,j}}$ the vector from vertex $i$ to vertex $j$ and $|\vec{r_{i,j}}|$ the length of said vector.

    Rewriting Coulomb's law to be useful in our research requires a bit more effort.
    However, it results in the very simplified equation below.
    
    This equation is the result of some assumptions.
    First off, the charge of both the particles is assumed to be 1.
    Furthermore, since more control over the strength of this force is desired Coulomb's constant can be merged with a weight constant $w_{r}$
    \begin{equation}
      F_{r}(i,j) = w_{r} \frac{\hat{r}_{j,i}}{|\vec{r_{j,i}}|^2}
    \end{equation}
    In this equation $\hat{r}_{j,i}$ is the normalized vector from vertex $j$ to vertex $i$. This order is chosen like this to ensure that the force applied to vertex $i$ is calculated instead of the force on vertex $j$.

    \subsubsection{Fruchterman Reingold}
    The Fruchterman Reingold algorithm on the other hand is named after its inventors.\cite{fruchterman1991graph}
    For the method Fruchterman and Reingold proposed there are only two principles for graph drawing, namely that connected vertices should be drawn near each other but not \emph{too} near.
    This algorithm can be seen as being based off of the idea of ideally distributed vertices.
    It does not focus so much on each individual node as much as how far all nodes should be apart from each other.
    Like the Hooke Coulomb algorithm it is based off of particle physics:
    All vertices repel each other whilst connected vertices are attracted to each other.
    This algorithm uses a few input variables of which three will be changed:
    \begin{itemize}
	  \item Force weight $w$
      \item The optimal distance between vertices $k_{i}$
      \item The measured area $A$
    \end{itemize}
    During our testing all of these will be directly or indirectly changed.
    $w$ is the weight by which both the attractive and the repulsive forces will be scaled, directly changing their influence on the vertices.
    $k_{i}$ on the other hand will not be directly changed, but by changing constant $C$ in its formula:
    \begin{equation}\label{eq:FR_k}
      k_{i} = C \sqrt{\frac{A}{N}}
    \end{equation}
	In this equation $C$ is a constant that will be changed during testing, $A$ is the aforementioned area, circular around the vertex $i$ that $k_i$ is calculated for. This area is varied by changing its radius $r$. $N$ is then the total amount of vertices in said area, including the vertex at its center.
	
    The constant $k_{i}$ plays an important part in calculation of both the attractive and repulsive forces.
    These can be calculated using formulas \ref{eq:FR_a} and \ref{eq:FR_r} respectively.
    \begin{equation}\label{eq:FR_a}
      f_{a}(i,j) = w \frac{|\vec{r_{i,j}}|^2}{k_{i}}
    \end{equation}
    \begin{equation}\label{eq:FR_r}
      f_{r}(i,j) = - w \frac{k_{i}^2}{|\vec{r_{i,j}}|}
    \end{equation}

    Unfortunately with just these formulas the system will not converge, so a cooling function is required. The output from this cooling function acts a limit on the distance a vertex may be moved after summing all the forces applied to it. As the name suggests, this function returns a lower value every iteration, thus ensuring increasingly small changes to the graph.
    
    For our experiment a simple hyperbolic cooling function will suffice:
    \begin{equation}
	    Cooling(i) = t_{0}^{1 - \frac{i}{n}}
    \end{equation}
    Where $t_{0}$ is the initial limit, $n$ is the total amount of iterations the algorithm will run for and $i$ is the current iteration.

    \subsubsection{Eades}
    One person who has made many contributions to the research of force directed graph drawing is Peter Eades.
    This algorithm is very similar to the Hooke-Coulomb one in that it uses the same laws, with an alteration to Hooke's spring law.
    The difference between them is the type of springs used.
    The force they exert in Hooke's law grows linearly, while it grows \emph{logarithmically} in Eades' algorithm.
	This means that the more a 'spring' is extended the speed at which the force increases slows down.
    The equation for the attractive force between vertices $i$ and $j$ in Eades' algorithm is:
    \begin{equation}\label{eq:Eades_a}
      f_a(i,j) = w_{a1} log_{2}(\frac{|\vec{r_{i,j}}|}{w_{a2}})
    \end{equation}

    Aside from this changed equation the algorithm remains exactly the same.
    This formula requires two constants $w_{a1}$ and $w_{a2}$ that will be changed during testing. \cite{eades1984heuristic}

  \section{Problem Discription}
    The aforementioned algorithms are meant to make graphs more readable, giving them a clear organized structure.
    Since readability is a rather vague and abstract measurement criteria in itself, there have to be concrete measurable properties that represent readability.
    The following properties can be used to express readability: \cite{kobourov2012spring}
    \begin{itemize}
      \item Uniformity of vertex distribution
      \item Uniformity of edge lengths
      \item Amount of edge crossings
    \end{itemize}
    The uniformity of vertex distribution can also be seen as the density of the vertices.
    Every vertex has an area with a fixed radius where the density can be calculated by counting the amount of vertices in that area. Division by the area is not necessary since the same area is used for all vertices, thus cancelling each other out.
    For a readable graph it is important that these densities are similar for all vertices.
    This characteristic of the uniformity of vertex distribution is then the coefficient of variation of the densities for all vertices, calculated by the standard deviation divided by the median. The lower this value, the better the graph is.

    With the uniformity of edge lengths, it is important that the lengths of all the edges are similar.
    A graph with a high variety of edge lengths is generally harder to read than a graph with edges of about equal lengths.
    This characteristic is measured with the coefficient of variation of all edge lengths. The lower this value, the better the graph is.

    For a good graph drawing, it is desirable to have as few edge crossings as possible, ideally none at all.
    Having a lot of edges that cross each other makes the graph look more chaotic and cluttered, thus making it harder to read. This characteristic is measured with the ratio of edges that cross any other edges to the total amount of edges. Again, the lower this value the better the graph is, $0$ when there are no edge crossings.

	Finally, the resulting values of these three measurements are summed to form the final quality measure. This Quality measure also indicates a better graph the smaller it is, just like its constituent components.

    Getting an as low as possible Quality value is what all the aforementioned algorithms strive for.
    Finding out which algorithm creates the graphs with the highest readability, which is to say the lowest Quality value, is what this research is meant to focus on.
    By doing these tests multiple times, we can conclude which algorithm gives the most readable graph from the results of these tests.
    Which brings us to our research question: Which force directed graph drawing algorithm yields the highest quality graphs?

  \section{The Experiment} % Beschrijving van het uitgevoerde experiment

  \section{Result Data} % Eindresultaten
  Now that the tests have been conducted this section will be used to illustrate the collected data, form hypotheses and test them. Due to the expansive size of our dataset 
  
  \subsection{Tabellen} % Uitgebeeld enzo
  \subsection{Grafieken}
  \subsection{Toelichting}
  \subsection{Statistische Hypothese}
  \subsection{De uitwerking hiervan}

  \section{Conclusion \& Discussion}
  \section{Reflection}

  \bibliography{verslag}{}
  \bibliographystyle{unsrt}
\end{document}
